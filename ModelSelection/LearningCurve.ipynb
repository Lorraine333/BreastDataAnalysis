{
 "metadata": {
  "name": "",
  "signature": "sha256:5d59a2509e8d193b6953346999d4235ac3e0e714337a671b06995b735304bff5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import pydotplus\n",
      "import math\n",
      "import sys\n",
      "from random import sample\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "from matplotlib import cm\n",
      "import sklearn\n",
      "from random import sample\n",
      "from sklearn import linear_model\n",
      "from sklearn import cross_validation\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import tree\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.learning_curve import learning_curve\n",
      "from __future__ import division # ensures that default division is real number division\n",
      "get_ipython().magic(u'matplotlib inline')\n",
      "%matplotlib\n",
      "mpl.rc('figure', figsize=[10,6]) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: MacOSX\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('wdbc.data.csv',header = None)\n",
      "base_names = ['radius', 'texture', 'perimeter', 'area', 'smooth', 'compact', 'concav', \n",
      "                 'conpoints', 'symmetry', 'fracdim']\n",
      "names = ['m' + name for name in base_names]\n",
      "names += ['s' + name for name in base_names]\n",
      "names += ['e' + name for name in base_names]\n",
      "names = ['id', 'class'] + names\n",
      "df.columns = names\n",
      "df.head()\n",
      "X = df.values[:,2:]\n",
      "y = df['class']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curve for decision tree\n",
      "sizeList = []\n",
      "accuList = []\n",
      "learnList = []\n",
      "for i in np.linspace(0.1,0.9,20):\n",
      "    size = int(i*X.shape[0])\n",
      "    sizeList.append(size)\n",
      "    bestScore = []\n",
      "    learnScore = []\n",
      "    for j in range(3):\n",
      "        rindex =  np.array(sample(xrange(len(df)),size))\n",
      "        sampleXY = df.ix[rindex]\n",
      "        testXY = df[~df.index.isin(rindex)]\n",
      "        sampleXY = sampleXY.reset_index()\n",
      "        testXY = testXY.reset_index()\n",
      "        del sampleXY['index']\n",
      "        del testXY['index']\n",
      "        testX = testXY.values[:,2:]\n",
      "        testY = testXY['class']\n",
      "    \n",
      "        sampleX = sampleXY.values[:,2:]\n",
      "        sampleY = sampleXY['class']\n",
      "        best = 0\n",
      "        for i in range(25):\n",
      "            kf = cross_validation.KFold(n=sampleY.shape[0],n_folds=5)\n",
      "            scoreEntropy = []\n",
      "            dtree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=i+1)\n",
      "    \n",
      "            for train_index, test_index in kf:\n",
      "                X_train, X_test = sampleX[train_index], sampleX[test_index]\n",
      "                y_train, y_test = sampleY[train_index], sampleY[test_index]\n",
      "                dtree.fit(X_train,y_train)\n",
      "                scoreEntropy.append(dtree.score(X_test, y_test))\n",
      "            score1 = np.mean(scoreEntropy)\n",
      "        \n",
      "            scoreGini = []\n",
      "            dtree1 = tree.DecisionTreeClassifier(criterion='gini', max_depth=i+1)\n",
      "            for train_index, test_index in kf:\n",
      "                X_train, X_test = sampleX[train_index], sampleX[test_index]\n",
      "                y_train, y_test = sampleY[train_index], sampleY[test_index]\n",
      "                dtree1.fit(X_train,y_train)\n",
      "                scoreGini.append(dtree1.score(X_test, y_test))\n",
      "            score2 = np.mean(scoreGini) \n",
      "        \n",
      "            if(score1<=score2):\n",
      "                better = score2\n",
      "                betterchoice = 'gini'\n",
      "            else:\n",
      "                better = score1\n",
      "                betterchoice = 'entropy'\n",
      "            if(better>best):\n",
      "                best = better \n",
      "                bestchoice = betterchoice\n",
      "                bestDepth = i+1\n",
      "        \n",
      "        optimalTree = tree.DecisionTreeClassifier(criterion=bestchoice, max_depth=bestDepth)\n",
      "        optimalTree.fit(sampleX,sampleY)\n",
      "        bestScore.append(optimalTree.score(X,y))\n",
      "        #bestScore.append(optimalTree.score(testX,testY))\n",
      "        learnScore.append(optimalTree.score(sampleX,sampleY))\n",
      "    learnList.append(np.mean(learnScore))\n",
      "    accuList.append(np.mean(bestScore))\n",
      "print sizeList,accuList,learnList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[56, 80, 104, 128, 152, 176, 200, 224, 248, 272, 296, 320, 344, 368, 392, 416, 440, 464, 488, 512] [0.91154071470415932, 0.91974223784417097, 0.92970123022847095, 0.94317516110134747, 0.94669009958992378, 0.93555946104276499, 0.94258933801991807, 0.95782073813708257, 0.96250732278851781, 0.96660808435852363, 0.96660808435852363, 0.97188049209138827, 0.96309314586994732, 0.96426479203280613, 0.97539543057996492, 0.97305213825424719, 0.98828353837141181, 0.98828353837141181, 0.99121265377855883, 0.98125366139425896] [0.98809523809523814, 1.0, 1.0, 1.0, 0.99780701754385959, 0.98295454545454541, 0.9966666666666667, 1.0, 1.0, 1.0, 1.0, 0.99895833333333339, 0.9941860465116279, 0.98641304347826086, 1.0, 0.98878205128205121, 1.0, 1.0, 1.0, 0.98828125]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(1)\n",
      "plt.title(\"Learning Curves (Decision Tree)\")\n",
      "\n",
      "plt.xlabel(\"Training examples\")\n",
      "plt.ylabel(\"Score\")\n",
      "plt.axis([0, 569, 0.5, 1.01])\n",
      "plt.plot(sizeList,accuList,'o-', color=\"r\",label=\"Testing score\")\n",
      "plt.plot(sizeList,learnList,'o-', color=\"g\",label=\"Training score\")\n",
      "plt.legend(loc = \"best\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'plt' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-92f244c27aa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Learning Curves (Decision Tree)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training examples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot learning curve for decision tree\n",
      "sizeList = []\n",
      "accuList = []\n",
      "learnList = []\n",
      "for i in np.linspace(0.1,0.9,20):\n",
      "    size = int(i*X.shape[0])\n",
      "    sizeList.append(size)\n",
      "    bestScore = []\n",
      "    learnScore = []\n",
      "    for j in range(3):\n",
      "        rindex =  np.array(sample(xrange(len(df)),size))\n",
      "        sampleXY = df.ix[rindex]\n",
      "        testXY = df[~df.index.isin(rindex)]\n",
      "        sampleXY = sampleXY.reset_index()\n",
      "        testXY = testXY.reset_index()\n",
      "        del sampleXY['index']\n",
      "        del testXY['index']\n",
      "        testX = testXY.values[:,2:]\n",
      "        testY = testXY['class']\n",
      "    \n",
      "        sampleX = sampleXY.values[:,2:]\n",
      "        sampleY = sampleXY['class']\n",
      "        best = 0\n",
      "        for i in range(25):\n",
      "            for j in range(5):\n",
      "                kf = cross_validation.KFold(n=sampleY.shape[0],n_folds=5)\n",
      "                scores = []\n",
      "                neigh = KNeighborsClassifier(n_neighbors=i+1, p = j+1)\n",
      "    \n",
      "                for train_index, test_index in kf:\n",
      "                    X_train, X_test = sampleX[train_index], sampleX[test_index]\n",
      "                    y_train, y_test = sampleY[train_index], sampleY[test_index]\n",
      "                    neigh.fit(X_train,y_train)\n",
      "                    scores.append(neigh.score(X_test, y_test))\n",
      "                score = np.mean(scores)\n",
      "\n",
      "                if(np.mean(score)>best):\n",
      "                    best = np.mean(score)\n",
      "                    bestNeighbors = i+1\n",
      "                    bestP = j+1\n",
      "    \n",
      "        optimalNeighbor = KNeighborsClassifier(n_neighbors=bestNeighbors, p = bestP)\n",
      "        optimalNeighbor.fit(sampleX,sampleY)        \n",
      "        #bestScore.append(optimalNeighbor.score(testX,testY))\n",
      "        bestScore.append(optimalNeighbor.score(X,y))\n",
      "        learnScore.append(optimalNeighbor.score(sampleX,sampleY))\n",
      "    learnList.append(np.mean(learnScore))\n",
      "    accuList.append(np.mean(bestScore))\n",
      "print sizeList,accuList,learnList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[56, 80, 104, 128, 152, 176, 200, 224, 248, 272, 296, 320, 344, 368, 392, 416, 440, 464, 488, 512] [0.91564147627416526, 0.91095489162273002, 0.9109548916227298, 0.90626830697129457, 0.93555946104276499, 0.94141769185705915, 0.94083186877562974, 0.93673110720562391, 0.94024604569420023, 0.94200351493848855, 0.93614528412419451, 0.95079086115992961, 0.93907439953134153, 0.94317516110134736, 0.94610427650849438, 0.95254833040421794, 0.9472759226713533, 0.95079086115992972, 0.948447568834212, 0.94434680726420617] [0.93452380952380965, 0.96250000000000002, 0.92307692307692302, 0.95052083333333337, 0.96052631578947378, 0.96969696969696972, 0.96666666666666667, 0.95833333333333337, 0.97177419354838712, 0.95098039215686259, 0.94144144144144148, 0.96770833333333339, 0.94282945736434109, 0.9375, 0.95068027210884354, 0.96314102564102555, 0.94545454545454544, 0.9533045977011495, 0.95286885245901642, 0.94466145833333337]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(1)\n",
      "plt.title(\"Learning Curves (K-Nearest-Neighbors)\")\n",
      "\n",
      "plt.xlabel(\"Training examples\")\n",
      "plt.ylabel(\"Score\")\n",
      "plt.axis([0, 569, 0.5, 1.01])\n",
      "plt.plot(sizeList,accuList,'o-', color=\"r\",label=\"Testing score\")\n",
      "plt.plot(sizeList,learnList,'o-', color=\"g\",label=\"Training score\")\n",
      "plt.legend(loc = \"best\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<matplotlib.legend.Legend at 0x11b12bb10>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}