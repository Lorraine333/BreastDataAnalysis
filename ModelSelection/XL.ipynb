{
 "metadata": {
  "name": "",
  "signature": "sha256:68d3ee5b1d3e84dc9ab47b9c2bd34632f87bfc33876ef0bf6b206ce945b51297"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import pydotplus\n",
      "import math\n",
      "import sys\n",
      "from random import sample\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "from matplotlib import cm\n",
      "import sklearn\n",
      "from sklearn import linear_model\n",
      "from sklearn import cross_validation\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import tree\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.learning_curve import learning_curve\n",
      "from __future__ import division # ensures that default division is real number division\n",
      "get_ipython().magic(u'matplotlib inline')\n",
      "%matplotlib\n",
      "mpl.rc('figure', figsize=[10,6]) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: MacOSX\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('wdbc.data.csv',header = None)\n",
      "base_names = ['radius', 'texture', 'perimeter', 'area', 'smooth', 'compact', 'concav', \n",
      "                 'conpoints', 'symmetry', 'fracdim']\n",
      "names = ['m' + name for name in base_names]\n",
      "names += ['s' + name for name in base_names]\n",
      "names += ['e' + name for name in base_names]\n",
      "names = ['id', 'class'] + names\n",
      "df.columns = names\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>class</th>\n",
        "      <th>mradius</th>\n",
        "      <th>mtexture</th>\n",
        "      <th>mperimeter</th>\n",
        "      <th>marea</th>\n",
        "      <th>msmooth</th>\n",
        "      <th>mcompact</th>\n",
        "      <th>mconcav</th>\n",
        "      <th>mconpoints</th>\n",
        "      <th>...</th>\n",
        "      <th>eradius</th>\n",
        "      <th>etexture</th>\n",
        "      <th>eperimeter</th>\n",
        "      <th>earea</th>\n",
        "      <th>esmooth</th>\n",
        "      <th>ecompact</th>\n",
        "      <th>econcav</th>\n",
        "      <th>econpoints</th>\n",
        "      <th>esymmetry</th>\n",
        "      <th>efracdim</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>   842302</td>\n",
        "      <td> M</td>\n",
        "      <td> 17.99</td>\n",
        "      <td> 10.38</td>\n",
        "      <td> 122.80</td>\n",
        "      <td> 1001.0</td>\n",
        "      <td> 0.11840</td>\n",
        "      <td> 0.27760</td>\n",
        "      <td> 0.3001</td>\n",
        "      <td> 0.14710</td>\n",
        "      <td>...</td>\n",
        "      <td> 25.38</td>\n",
        "      <td> 17.33</td>\n",
        "      <td> 184.60</td>\n",
        "      <td> 2019.0</td>\n",
        "      <td> 0.1622</td>\n",
        "      <td> 0.6656</td>\n",
        "      <td> 0.7119</td>\n",
        "      <td> 0.2654</td>\n",
        "      <td> 0.4601</td>\n",
        "      <td> 0.11890</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>   842517</td>\n",
        "      <td> M</td>\n",
        "      <td> 20.57</td>\n",
        "      <td> 17.77</td>\n",
        "      <td> 132.90</td>\n",
        "      <td> 1326.0</td>\n",
        "      <td> 0.08474</td>\n",
        "      <td> 0.07864</td>\n",
        "      <td> 0.0869</td>\n",
        "      <td> 0.07017</td>\n",
        "      <td>...</td>\n",
        "      <td> 24.99</td>\n",
        "      <td> 23.41</td>\n",
        "      <td> 158.80</td>\n",
        "      <td> 1956.0</td>\n",
        "      <td> 0.1238</td>\n",
        "      <td> 0.1866</td>\n",
        "      <td> 0.2416</td>\n",
        "      <td> 0.1860</td>\n",
        "      <td> 0.2750</td>\n",
        "      <td> 0.08902</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 84300903</td>\n",
        "      <td> M</td>\n",
        "      <td> 19.69</td>\n",
        "      <td> 21.25</td>\n",
        "      <td> 130.00</td>\n",
        "      <td> 1203.0</td>\n",
        "      <td> 0.10960</td>\n",
        "      <td> 0.15990</td>\n",
        "      <td> 0.1974</td>\n",
        "      <td> 0.12790</td>\n",
        "      <td>...</td>\n",
        "      <td> 23.57</td>\n",
        "      <td> 25.53</td>\n",
        "      <td> 152.50</td>\n",
        "      <td> 1709.0</td>\n",
        "      <td> 0.1444</td>\n",
        "      <td> 0.4245</td>\n",
        "      <td> 0.4504</td>\n",
        "      <td> 0.2430</td>\n",
        "      <td> 0.3613</td>\n",
        "      <td> 0.08758</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 84348301</td>\n",
        "      <td> M</td>\n",
        "      <td> 11.42</td>\n",
        "      <td> 20.38</td>\n",
        "      <td>  77.58</td>\n",
        "      <td>  386.1</td>\n",
        "      <td> 0.14250</td>\n",
        "      <td> 0.28390</td>\n",
        "      <td> 0.2414</td>\n",
        "      <td> 0.10520</td>\n",
        "      <td>...</td>\n",
        "      <td> 14.91</td>\n",
        "      <td> 26.50</td>\n",
        "      <td>  98.87</td>\n",
        "      <td>  567.7</td>\n",
        "      <td> 0.2098</td>\n",
        "      <td> 0.8663</td>\n",
        "      <td> 0.6869</td>\n",
        "      <td> 0.2575</td>\n",
        "      <td> 0.6638</td>\n",
        "      <td> 0.17300</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 84358402</td>\n",
        "      <td> M</td>\n",
        "      <td> 20.29</td>\n",
        "      <td> 14.34</td>\n",
        "      <td> 135.10</td>\n",
        "      <td> 1297.0</td>\n",
        "      <td> 0.10030</td>\n",
        "      <td> 0.13280</td>\n",
        "      <td> 0.1980</td>\n",
        "      <td> 0.10430</td>\n",
        "      <td>...</td>\n",
        "      <td> 22.54</td>\n",
        "      <td> 16.67</td>\n",
        "      <td> 152.20</td>\n",
        "      <td> 1575.0</td>\n",
        "      <td> 0.1374</td>\n",
        "      <td> 0.2050</td>\n",
        "      <td> 0.4000</td>\n",
        "      <td> 0.1625</td>\n",
        "      <td> 0.2364</td>\n",
        "      <td> 0.07678</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 32 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "         id class  mradius  mtexture  mperimeter   marea  msmooth  mcompact  \\\n",
        "0    842302     M    17.99     10.38      122.80  1001.0  0.11840   0.27760   \n",
        "1    842517     M    20.57     17.77      132.90  1326.0  0.08474   0.07864   \n",
        "2  84300903     M    19.69     21.25      130.00  1203.0  0.10960   0.15990   \n",
        "3  84348301     M    11.42     20.38       77.58   386.1  0.14250   0.28390   \n",
        "4  84358402     M    20.29     14.34      135.10  1297.0  0.10030   0.13280   \n",
        "\n",
        "   mconcav  mconpoints    ...     eradius  etexture  eperimeter   earea  \\\n",
        "0   0.3001     0.14710    ...       25.38     17.33      184.60  2019.0   \n",
        "1   0.0869     0.07017    ...       24.99     23.41      158.80  1956.0   \n",
        "2   0.1974     0.12790    ...       23.57     25.53      152.50  1709.0   \n",
        "3   0.2414     0.10520    ...       14.91     26.50       98.87   567.7   \n",
        "4   0.1980     0.10430    ...       22.54     16.67      152.20  1575.0   \n",
        "\n",
        "   esmooth  ecompact  econcav  econpoints  esymmetry  efracdim  \n",
        "0   0.1622    0.6656   0.7119      0.2654     0.4601   0.11890  \n",
        "1   0.1238    0.1866   0.2416      0.1860     0.2750   0.08902  \n",
        "2   0.1444    0.4245   0.4504      0.2430     0.3613   0.08758  \n",
        "3   0.2098    0.8663   0.6869      0.2575     0.6638   0.17300  \n",
        "4   0.1374    0.2050   0.4000      0.1625     0.2364   0.07678  \n",
        "\n",
        "[5 rows x 32 columns]"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
      "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 10)):\n",
      "    \n",
      "    plt.figure()\n",
      "    plt.title(title)\n",
      "    if ylim is not None:\n",
      "        plt.ylim(*ylim)\n",
      "    plt.xlabel(\"Training examples\")\n",
      "    plt.ylabel(\"Score\")\n",
      "    train_sizes, train_scores, test_scores = learning_curve(\n",
      "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
      "    train_scores_mean = np.mean(train_scores, axis=1)\n",
      "    test_scores_mean = np.mean(test_scores, axis=1)\n",
      "    plt.grid()\n",
      "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"g\",\n",
      "             label=\"Training score\")\n",
      "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"r\",\n",
      "             label=\"Testing score\")\n",
      "\n",
      "    plt.legend(loc=\"best\")\n",
      "    return plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df.values[:,2:]\n",
      "y = df['class']\n",
      "title = \"Learning Curves (Logistic Regression)\"\n",
      "estimator = linear_model.LogisticRegression()\n",
      "\n",
      "plot_learning_curve(estimator, title, X, y, ylim=(0.5, 1.01), cv=5)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#find best max_depth for decision tree\n",
      "best = 0\n",
      "for i in range(25):\n",
      "    kf = cross_validation.KFold(n=X.shape[0],n_folds=5)\n",
      "    score = []\n",
      "    dtree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=i+1)\n",
      "    \n",
      "    for train_index, test_index in kf:\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        y_train, y_test = y[train_index], y[test_index]\n",
      "        dtree.fit(X_train,y_train)\n",
      "        score.append(dtree.score(X_test, y_test))\n",
      "    if(np.mean(score)>best):\n",
      "        best = np.mean(score)\n",
      "        bestDepth = i+1\n",
      "print bestDepth\n",
      "\n",
      "    \n",
      "#find better criterion\n",
      "dtree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=bestDepth)\n",
      "kf = cross_validation.KFold(n=X.shape[0],n_folds=5)\n",
      "score = []\n",
      "for train_index, test_index in kf:\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        y_train, y_test = y[train_index], y[test_index]\n",
      "        dtree.fit(X_train,y_train)\n",
      "        score.append(dtree.score(X_test, y_test))\n",
      "\n",
      "\n",
      "dtree = tree.DecisionTreeClassifier(criterion='gini', max_depth=bestDepth)\n",
      "kf = cross_validation.KFold(n=X.shape[0],n_folds=5)\n",
      "score1 = []\n",
      "for train_index, test_index in kf:\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        y_train, y_test = y[train_index], y[test_index]\n",
      "        dtree.fit(X_train,y_train)\n",
      "        score1.append(dtree.score(X_test, y_test))\n",
      "\n",
      "if(np.mean(score)>np.mean(score1)):\n",
      "    bestCriterion = 'entropy'\n",
      "else:\n",
      "    bestCriterion = 'gini'\n",
      "print bestCriterion"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "24\n",
        "entropy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title = \"Learning Curves (Decision Tree)\"\n",
      "estimator = tree.DecisionTreeClassifier(criterion=bestCriterion, max_depth=10)\n",
      "\n",
      "plot_learning_curve(estimator, title, X, y, ylim=(0.5, 1.01), cv=5)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "#find best n_neighbors for k-Nearest neighbors\n",
      "best = 0\n",
      "for i in range(20):\n",
      "    kf = cross_validation.KFold(n=X.shape[0],n_folds=5)\n",
      "    score = []\n",
      "    neigh = KNeighborsClassifier(n_neighbors=i+1)\n",
      "    \n",
      "    for train_index, test_index in kf:\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        y_train, y_test = y[train_index], y[test_index]\n",
      "        neigh.fit(X_train,y_train)\n",
      "        score.append(neigh.score(X_test, y_test))\n",
      "    if(np.mean(score)>best):\n",
      "        best = np.mean(score)\n",
      "        bestNeighbors = i+1\n",
      "print bestNeighbors\n",
      "\n",
      "    \n",
      "#find better p for k-Nearest neighbors\n",
      "best=0\n",
      "for j in range(5):\n",
      "    kf = cross_validation.KFold(n=X.shape[0],n_folds=5)\n",
      "    score = []\n",
      "    neigh = KNeighborsClassifier(n_neighbors=bestNeighbors,p = j+1)\n",
      "    \n",
      "    for train_index, test_index in kf:\n",
      "        X_train, X_test = X[train_index], X[test_index]\n",
      "        y_train, y_test = y[train_index], y[test_index]\n",
      "        neigh.fit(X_train,y_train)\n",
      "        score.append(neigh.score(X_test, y_test))\n",
      "    if(np.mean(score)>best):\n",
      "        best = np.mean(score)\n",
      "        bestP = j+1\n",
      "print bestP"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title = \"Learning Curves (k-Nearest Neighbors)\"\n",
      "estimator = KNeighborsClassifier(n_neighbors=bestNeighbors,p = bestP)\n",
      "\n",
      "plot_learning_curve(estimator, title, X, y, ylim=(0.3, 1.01), cv=5)\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}